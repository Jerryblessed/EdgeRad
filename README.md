# ğŸ¥ EdgeRad: The Offline AI Radiologist

> *Bringing specialist-grade diagnostics to rural clinics â€” no internet required.*

[![MedGemma](https://img.shields.io/badge/Powered%20by-MedGemma--4B--IT-blue?logo=google)](https://huggingface.co/google/medgemma-4b-it)
[![HAI-DEF](https://img.shields.io/badge/Google-HAI--DEF-green)](https://health.google/health-research/applied-health-ai/)
[![License](https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey)](https://creativecommons.org/licenses/by/4.0/)
[![Kaggle](https://img.shields.io/badge/Kaggle-MedGemma%20Impact%20Challenge-orange?logo=kaggle)](https://kaggle.com/competitions/med-gemma-impact-challenge)

---

## ğŸŒ The Problem

In rural healthcare facilities across West Africa, two critical resources are consistently scarce: **specialist radiologists** and **reliable internet connectivity**.

- Patients wait **weeks** for X-ray interpretations that must be physically transported to city hospitals
- Cloud-based AI solutions **vanish** the moment the network drops
- Sending sensitive patient images to the cloud raises **data privacy concerns** in regions with developing data protection infrastructure

> *We don't just need "AI in Healthcare." We need AI at the Edge.*

---

## ğŸ’¡ The Solution

**EdgeRad** is a lightweight, privacy-first diagnostic assistant powered by Google's HAI-DEF **MedGemma-4B-IT** model. It runs **100% offline** on consumer hardware, allowing nurses and general practitioners to upload medical images (chest X-rays, skin lesions, CT scans) and receive immediate clinical-grade analysis â€” with or without an internet connection.

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        EDGERAD SYSTEM                           â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   FRONTEND   â”‚     â”‚            BACKEND CORE              â”‚  â”‚
â”‚  â”‚              â”‚     â”‚                                      â”‚  â”‚
â”‚  â”‚   Gradio UI  â”‚â”€â”€â”€â”€â–¶â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â”‚
â”‚  â”‚              â”‚     â”‚  â”‚   Adaptive Loading Engine   â”‚    â”‚  â”‚
â”‚  â”‚  â€¢ Image     â”‚     â”‚  â”‚                             â”‚    â”‚  â”‚
â”‚  â”‚    Upload    â”‚     â”‚  â”‚  VRAM â‰¥ 14GB â†’ Float16      â”‚    â”‚  â”‚
â”‚  â”‚  â€¢ Clinical  â”‚     â”‚  â”‚  VRAM 8-14GB â†’ 8-bit        â”‚    â”‚  â”‚
â”‚  â”‚    Question  â”‚     â”‚  â”‚  VRAM < 8GB  â†’ 4-bit NF4   â”‚    â”‚  â”‚
â”‚  â”‚  â€¢ Analysis  â”‚     â”‚  â”‚  No GPU      â†’ CPU Fallback â”‚    â”‚  â”‚
â”‚  â”‚    Output    â”‚     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚
â”‚  â”‚              â”‚     â”‚                 â”‚                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â”‚
â”‚                        â”‚  â”‚     MedGemma-4B-IT Model    â”‚    â”‚  â”‚
â”‚                        â”‚  â”‚   (google/medgemma-4b-it)   â”‚    â”‚  â”‚
â”‚                        â”‚  â”‚                             â”‚    â”‚  â”‚
â”‚                        â”‚  â”‚  â€¢ Vision Encoder           â”‚    â”‚  â”‚
â”‚                        â”‚  â”‚  â€¢ Language Decoder         â”‚    â”‚  â”‚
â”‚                        â”‚  â”‚  â€¢ Multimodal Fusion        â”‚    â”‚  â”‚
â”‚                        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚
â”‚                        â”‚                 â”‚                    â”‚  â”‚
â”‚                        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â”‚
â”‚                        â”‚  â”‚     Inference Pipeline      â”‚    â”‚  â”‚
â”‚                        â”‚  â”‚                             â”‚    â”‚  â”‚
â”‚                        â”‚  â”‚  AutoProcessor (chat tmpl)  â”‚    â”‚  â”‚
â”‚                        â”‚  â”‚  torch.inference_mode()     â”‚    â”‚  â”‚
â”‚                        â”‚  â”‚  Deterministic generation   â”‚    â”‚  â”‚
â”‚                        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                  DEPLOYMENT TARGETS                      â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚   â˜ï¸  Google Colab T4      ğŸ–¥ï¸  RTX 3060 Laptop           â”‚   â”‚
â”‚  â”‚   ğŸ¤–  NVIDIA Jetson Orin  ğŸ’»  Any CUDA-capable device    â”‚   â”‚
â”‚  â”‚                   ğŸ”Œ  Fully Offline                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

```
  Medical Image (X-ray / CT / Skin Lesion)
          â”‚
          â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  PIL Image    â”‚  â† Gradio handles upload & conversion
  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  apply_chat_template()    â”‚  â† Formats image + question into
  â”‚  [image] + [text prompt]  â”‚    MedGemma's expected input format
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   MedGemma-4B-IT          â”‚  â† Multimodal inference
  â”‚   Vision + Language       â”‚    (image & text processed together)
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Token Decoding           â”‚  â† Strips prompt tokens, decodes output
  â”‚  skip_special_tokens=True â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
      Clinical Analysis Text
```

---

## âš¡ Adaptive GPU Loading

EdgeRad automatically detects available hardware and loads the model at the optimal precision â€” no configuration needed.

| Hardware | VRAM | Mode | Memory Used | Quality |
|---|---|---|---|---|
| A100 / H100 / RTX 4090 | 40â€“80 GB | Float16 | ~8 GB | â­â­â­ Best |
| T4 / RTX 3060â€“3090 | 14â€“24 GB | Float16 | ~8 GB | â­â­â­ Best |
| Mid-range GPU | 8â€“14 GB | 8-bit | ~4.5 GB | â­â­ Good |
| Entry-level GPU | < 8 GB | 4-bit NF4 | ~3.6 GB | â­â­ Solid |
| No GPU | CPU RAM | Float32 | ~16 GB RAM | â­ Slow |

---

## ğŸš€ Quick Start

### Option 1 â€” Google Colab (Recommended)

1. Open the notebook in Colab
2. Run all cells
3. Authenticate with your Hugging Face token when prompted
4. Open the Gradio public URL and start analyzing

### Option 2 â€” Local Setup

```bash
# Clone the repo
git clone https://github.com/Jerryblessed/EdgeRad.git
cd EdgeRad

# Install dependencies
pip install torch transformers accelerate bitsandbytes gradio huggingface_hub pillow

# Run
python app.py
```

### Requirements

- Python 3.9+
- CUDA-compatible GPU recommended (CPU fallback available)
- Hugging Face account with MedGemma access approved
  - Request access at: https://huggingface.co/google/medgemma-4b-it

---

## ğŸ” Authentication

EdgeRad uses your Hugging Face token to download the MedGemma model on first run. The model is then cached locally â€” subsequent runs work **fully offline**.

```python
# You will be prompted to enter your token on first run
# Generate a token at: https://huggingface.co/settings/tokens
# Select "Read" permission only
```

> âš ï¸ **Never commit your token to GitHub.** Use environment variables or Colab Secrets.

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|---|---|
| Model | `google/medgemma-4b-it` (HAI-DEF) |
| Inference | PyTorch + Hugging Face Transformers |
| Quantization | bitsandbytes (4-bit NF4 / 8-bit) |
| Acceleration | Hugging Face Accelerate |
| Frontend | Gradio |
| Deployment | Docker-ready, fully offline |

---

## ğŸ“Š Performance

| Metric | Value |
|---|---|
| Model Parameters | 4 Billion |
| VRAM (4-bit mode) | ~3.6 GB |
| VRAM (float16 mode) | ~8 GB |
| Avg. Inference Time | 5â€“15 seconds (T4 GPU) |
| Internet Required | âŒ After initial download |

---

## ğŸŒ Impact

EdgeRad is specifically designed for deployment in **low-resource clinical settings**:

- **Rural clinics in West Africa** with intermittent connectivity
- **Field hospitals** and mobile medical units
- **Community health centers** without radiology departments
- Any setting where **patient data privacy** is a priority

A single deployment requires one internet connection to download the model. After that, the ethernet cable can be unplugged permanently.

---

## âš ï¸ Disclaimer

EdgeRad is a research and demonstration tool developed for the MedGemma Impact Challenge. All AI-generated outputs **must be reviewed and verified by a qualified medical professional** before being used in any clinical decision-making context.

---

## ğŸ“„ License

This project is licensed under [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/) in accordance with the MedGemma Impact Challenge rules.

---

## ğŸ† Competition

Submitted to the **MedGemma Impact Challenge** on Kaggle by Google Research.
- Main Track
- The Edge AI Prize Track

---

*Built with â¤ï¸ for the clinics that need it most.*
